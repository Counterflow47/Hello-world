import os
import torch
import numpy as np
import cv2
from mobile_sam import sam_model_registry, SamPredictor
from app.core.config import get_settings

settings = get_settings()

class SamService:
    def __init__(self):
        self.predictor = None
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        # å°è¯•å¤šä¸ªå¯èƒ½çš„æ¨¡å‹è·¯å¾„
        self.possible_paths = [
            "mobile_sam.pt",
            "./mobile_sam.pt",
            "./backend/mobile_sam.pt",
            "./app/services/mobile_sam.pt",
            "./data/models/mobile_sam.pt",
            "./models/mobile_sam.pt",
        ]

    async def initialize(self):
        """åˆå§‹åŒ– MobileSAM æ¨¡å‹"""
        print(f"ğŸ”„ æ­£åœ¨åŠ è½½ MobileSAM æ¨¡å‹ ({self.device})...")
        try:
            # åŠ è½½æ¨¡å‹ (vit_t æ˜¯ MobileSAM çš„ç±»å‹)
            model_type = "vit_t"
            
            # å°è¯•æ‰€æœ‰å¯èƒ½çš„è·¯å¾„
            model_path = None
            for path in self.possible_paths:
                if os.path.exists(path):
                    model_path = path
                    break
            
            if not model_path:
                raise FileNotFoundError(f"æœªæ‰¾åˆ° MobileSAM æ¨¡å‹æ–‡ä»¶ã€‚è¯·å°† mobile_sam.pt æ”¾åœ¨ä»¥ä¸‹ä»»ä¸€ç›®å½•ï¼š\n{chr(10).join(self.possible_paths)}")
            
            print(f"ğŸ“¦ æ‰¾åˆ°æ¨¡å‹æ–‡ä»¶: {model_path}")
            sam = sam_model_registry[model_type](checkpoint=model_path)
            sam.to(device=self.device)
            sam.eval()
            
            self.predictor = SamPredictor(sam)
            print("âœ… MobileSAM æ¨¡å‹åŠ è½½æˆåŠŸ")
        except Exception as e:
            print(f"âŒ MobileSAM æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            # è¿™é‡Œå¯ä»¥é€‰æ‹©æ˜¯å¦æŠ›å‡ºå¼‚å¸¸ï¼Œæˆ–è€…å…è®¸æœåŠ¡åœ¨æ²¡æœ‰SAMçš„æƒ…å†µä¸‹å¯åŠ¨
            # raise e

    async def cleanup(self):
        """æ¸…ç†æ˜¾å­˜"""
        if self.predictor:
            del self.predictor
            if self.device == "cuda":
                torch.cuda.empty_cache()
            print("âœ… MobileSAM èµ„æºå·²é‡Šæ”¾")

    def predict_mask_and_crop(self, image_rgb: np.ndarray, x: int, y: int):
        """æ ¸å¿ƒä¸šåŠ¡é€»è¾‘ï¼šç‚¹å‡» -> é¢„æµ‹ -> æŠ å›¾"""
        if not self.predictor:
            raise RuntimeError("SAM æ¨¡å‹æœªåˆå§‹åŒ–")

        # 1. è®¾ç½®å›¾åƒ
        self.predictor.set_image(image_rgb)

        # 2. é¢„æµ‹
        input_point = np.array([[x, y]])
        input_label = np.array([1]) # 1=å‰æ™¯

        masks, scores, _ = self.predictor.predict(
            point_coords=input_point,
            point_labels=input_label,
            multimask_output=True,
        )

        # 3. é€‰æœ€å¥½çš„ mask
        best_idx = np.argmax(scores)
        best_mask = masks[best_idx]

        # 4. æŠ å›¾
        cropped_img = np.zeros_like(image_rgb)
        cropped_img[best_mask] = image_rgb[best_mask]

        # 5. è£å‰ªé»‘è¾¹ (åªä¿ç•™ç‰©ä½“éƒ¨åˆ†)
        y_indices, x_indices = np.where(best_mask)
        if len(y_indices) > 0:
            x_min, x_max = x_indices.min(), x_indices.max()
            y_min, y_max = y_indices.min(), y_indices.max()
            # å¢åŠ ä¸€ç‚¹ padding
            pad = 10
            h, w, _ = image_rgb.shape
            y_min = max(0, y_min - pad)
            y_max = min(h, y_max + pad)
            x_min = max(0, x_min - pad)
            x_max = min(w, x_max + pad)
            
            # åªè£å‰ªç‰©ä½“åŒºåŸŸï¼Œå…¶ä»–åŒºåŸŸå…¨éƒ¨å»æ‰
            final_crop = cropped_img[y_min:y_max, x_min:x_max]
            return final_crop, float(scores[best_idx])
        
        return cropped_img, 0.0
